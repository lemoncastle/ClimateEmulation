{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac5fb68-e678-4302-a936-a463e96fe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colors\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccd7ed-0bc6-4477-a8a7-563c7bd885c5",
   "metadata": {},
   "source": [
    "### Pattern Scaling\n",
    "\n",
    "https://link.springer.com/article/10.1007/s10584-013-1032-9\n",
    "\n",
    "https://web.stanford.edu/group/emf-research/docs/sm/2016/ClaudiaT_PatternScaling.pdf\n",
    "\n",
    "Search assist says **NOTE THIS IS AI**t- \n",
    "\n",
    "\n",
    "Pattern scaling is a method used in climate science to estimate how changes in global temperature affect regional climate variables, like precipitation and temperature. It involves using existing climate model outputs to create simplified projections for future climate scenarios, making it easier and less costly to analyze potential climate impacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519429b-0c2e-45b5-8b70-74b22ccef17b",
   "metadata": {},
   "source": [
    "says only need\n",
    "\n",
    "the actual GCM field (tas_truth)\n",
    "\n",
    "the global mean temperature (tas_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a236c834-ddf9-46a3-900b-36602bc573af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your own data_path\n",
    "data_path = \"./dataset/\"\n",
    "\n",
    "#Get test data (SSP 245)\n",
    "test_Y = xr.open_dataset(data_path + 'outputs_ssp245.nc').compute()\n",
    "test_X = xr.open_dataset(data_path + 'inputs_ssp245.nc').compute()\n",
    "\n",
    "# Get one combined historical + ssp585 timeseries for now\n",
    "X = xr.open_mfdataset([data_path + 'inputs_historical.nc', data_path + 'inputs_ssp585.nc']).compute()\n",
    "# Take the 2nd ensemble member for the historical (the first one has some missing DTR values for some reason...) and the 1st (only) one for SSP585\n",
    "Y = xr.concat([xr.open_dataset(data_path + 'outputs_historical.nc').sel(member=2), xr.open_dataset(data_path + 'outputs_ssp585.nc').sel(member=1)], dim='time').compute()\n",
    "\n",
    "# Convert the precip values to mm/day\n",
    "Y[\"pr\"] *= 86400\n",
    "Y[\"pr90\"] *= 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77449fae-7158-4ebc-a735-4bcb74dd2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_mean(field):\n",
    "    # area weights (cos(lat))\n",
    "    weights = np.cos(np.deg2rad(field.lat))\n",
    "    weights /= weights.mean()\n",
    "\n",
    "    return (field * weights).mean(dim=(\"lat\", \"lon\"))\n",
    "\n",
    "def compute_pattern_scaling(truth, global_ts, baseline=(1850,1900)):\n",
    "    # anomalies\n",
    "    da = truth - truth.sel(time=slice(*baseline)).mean(\"time\")\n",
    "    gm = global_ts - global_ts.sel(time=slice(*baseline)).mean(\"time\")\n",
    "\n",
    "    # regression slope at each grid cell = pattern\n",
    "    S = (da * gm).mean(\"time\") / (gm**2).mean(\"time\")\n",
    "    return S\n",
    "\n",
    "def rmse(true, pred):\n",
    "    return float(np.sqrt(((true - pred) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dce5c6-47df-44d8-a9e1-3f90d38f7bfa",
   "metadata": {},
   "source": [
    "- called single regresser pattern scaling\n",
    "- Y(x,y,t)≈S(x,y)⋅G(t)\n",
    "    - Y is the local climate variable (tas).\n",
    "    - G(t) is the global mean temperature.\n",
    "    - S(x,y) is the regression slope at each grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bf513d8-7188-4e6b-abd2-39e0e02f64c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE tas: 0.7171458521812378\n"
     ]
    }
   ],
   "source": [
    "tas_global = compute_global_mean(Y[\"tas\"])\n",
    "tas_global_TEST = compute_global_mean(test_Y[\"tas\"])\n",
    "\n",
    "S_tas = compute_pattern_scaling(Y[\"tas\"], tas_global)\n",
    "\n",
    "tas_scaled_TEST = S_tas * tas_global_TEST\n",
    "\n",
    "rmse_tas = rmse(test_Y[\"tas\"], tas_scaled_TEST)\n",
    "print(\"RMSE tas:\", rmse_tas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99337750",
   "metadata": {},
   "source": [
    "this is the simplest model that I could make in 2 hours after learning what pattern scaling is. not great\n",
    "\n",
    "A model involving linear regression will be looked at later\n",
    "- also involving data from SSP126, 370 and 585.\n",
    "\n",
    "the provided notebook on repo is a good baseline.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
